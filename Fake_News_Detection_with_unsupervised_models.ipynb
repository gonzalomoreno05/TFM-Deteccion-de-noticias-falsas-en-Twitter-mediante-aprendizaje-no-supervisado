{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n",
        "\n"
      ],
      "metadata": {
        "id": "Qzph2a4-IwIH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xo6X00TGKinE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a6c751-78ee-4598-9d26-d08a4708e34d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "from urllib. parse import urlparse                                              # Para extraer el dominio de una url\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas import json_normalize\n",
        "\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from string import punctuation                                                  # Signos de puntuación\n",
        "from nltk.corpus import stopwords                                               # StopWords\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer                     # Análisis de sentimiento\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from nltk.stem.porter import *                                                  # Stemming\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Dimensionality reduction libraries\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import gensim\n",
        "\n",
        "# Librerías de cada uno de los modelos de aprendizaje no supervisado que se van a utilizar durante el proyecto\n",
        "from sklearn.cluster import KMeans, AffinityPropagation, AgglomerativeClustering, Birch, DBSCAN, MiniBatchKMeans, MeanShift, OPTICS, SpectralClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score, calinski_harabasz_score, davies_bouldin_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recolección de datos"
      ],
      "metadata": {
        "id": "7kbVNea9I5D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definición de token de acceso a la API de Twitter"
      ],
      "metadata": {
        "id": "GZWAqp_727mE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2j9-cj5X-wXo"
      },
      "outputs": [],
      "source": [
        "os.environ['BEARER_TOKEN'] ='AAAAAAAAAAAAAAAAAAAAADTYSgEAAAAAeZ3oZmAAU5Wy%2BD8JDb4oufgY4cU%3DsJ09bufT525BDLTwI6DsDW4rCuo57Y5eXUJFwhIRkouvMZbQGH'\n",
        "\n",
        "def auth():\n",
        "    return os.getenv('BEARER_TOKEN')\n",
        "\n",
        "def create_headers(bearer_token):\n",
        "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
        "    return headers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Método para crear la url de las diferentes peticiones que se van a realizar a la API de Twitter para la búsqueda de noticias, en ella se seleccionan los diferentes campos a rellenar en la query a realizar a dicha API, y que se mencionan a continuación:\n",
        "\n",
        "- La variable 'keyword' relativa a la query representa el filtro utilizado en la búsqueda de noticias, el cual es incluido como atributo de creación de la url de la petición.\n",
        "\n",
        "- Las variables 'start_date' y 'end_date' también se introducen como atributos de la función de creación de la url, y representan el momento a partir del cual empezar a recopilar tweets, y el momento en el que dejar de recopilarlos.\n",
        "\n",
        "- La variable 'max_results' también se introduce como atributo de la función y sirve para indicar un número concreto de tweets a recopilar, el cual esta inicializado a 10, y tiene como máximo valor, debido a las limitaciones que presenta la API de Twitter en su formato de developer para estudiantes, de 500 peticiones por cada query.\n",
        "\n",
        "El resto de parámetros que contiene la query representan los datos que se solicita que devuelva dicha query, en este caso, el id del autor del tweet (author_id), el texto del tweet (text), el momento en el que se publicó dicho tweet (created_at)... Estos parámetros pueden ser modificados, incluyendo o sustituyendolos por los aportados como comentario para ampliar o modificar la información devuelta por la query.\n"
      ],
      "metadata": {
        "id": "O763rDts3Ezk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nfr25CfrL4pH"
      },
      "outputs": [],
      "source": [
        "def create_url(keyword, start_date,end_date,max_results = 10):\n",
        "\n",
        "    search_url = \"https://api.twitter.com/2/tweets/search/all\"      # Change to the endpoint you want to collect data from\n",
        "\n",
        "    # Change params based on the endpoint you are using\n",
        "    query_params = {'query': keyword, \n",
        "                    'start_time': start_date, \n",
        "                    'end_time': end_date, \n",
        "                    'max_results': max_results, \n",
        "                    'expansions': 'author_id', #in_reply_to_user_id, author_id, geo.place_id',\n",
        "                    'tweet.fields': 'text', # id,text, author_id, in_reply_to_user_id, geo, conversation_id, created_at,lang,public_metrics, referenced_tweets, reply_settings, source',\n",
        "                    'tweet.fields': 'created_at',\n",
        "                    #'tweet.fields': 'public_metrics',\n",
        "                    'user.fields': 'name',#id, name, username, created_at, description, public_metrics, verified',\n",
        "                    'user.fields': 'verified',\n",
        "                    'user.fields': 'public_metrics',\n",
        "                    'place.fields': 'country',# full_name, id, country, country_code, geo, name, place_type',\n",
        "                    'next_token': {}}\n",
        "    \n",
        "    return (search_url, query_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omuh0ln9Llkg"
      },
      "outputs": [],
      "source": [
        "def connect_to_endpoint(url, headers, params, next_token = None):\n",
        "    params['next_token'] = next_token   #params object received from create_url function\n",
        "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
        "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(response.status_code, response.text)\n",
        "    return response.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definición de las variables que se van a introducir como atributos a la función de creación de la query a la API de Twitter"
      ],
      "metadata": {
        "id": "vzMDzQ5a5Mjk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlHc_8l3m6rq",
        "outputId": "aa1a88e0-795e-4635-d020-5c48b11ab198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Endpoint Response Code: 200\n"
          ]
        }
      ],
      "source": [
        "#Recolección de noticias en inglés\n",
        "indice = 0\n",
        "dfen = pd.DataFrame()\n",
        "\n",
        "while indice < 50000:                                                           # Bucle para la recopilación de un total de 50.000 tweets (El máximo que se permite con los permisos actuales en la API de Twitter antes de un periodo de espera es de 150.000)\n",
        "\n",
        "  # Definición de las variables para crear la URL de la petición a la API de Twitter\n",
        "  bearer_token = auth()\n",
        "  headers = create_headers(bearer_token)\n",
        "  keyword = \"#news -is:retweet has:links lang:en\"                               # Filtros: Tweets con hashtag = \"news\" (#news), que NO sean retweets (-is:retweet), que contengan links (has:links) y estén en inglés (lang:en)\n",
        "  start_time = \"2022-01-01T00:00:00.000Z\"                                       # Fecha de inicio de recolección de tweets\n",
        "  end_time = \"2022-05-12T00:00:00.000Z\"                                         # Fecha del último tweet posible\n",
        "  max_results = 500                                                             # Máxima cantidad de tweets que puede devolver\n",
        "  \n",
        "  if indice != 0:\n",
        "    end_time = df1['created_at'][len(df1)-1]\n",
        "  \n",
        "  # Creación de la petición a la API de Twitter\n",
        "  url = create_url(keyword, start_time, end_time, max_results)                  # Creación de la URL\n",
        "  json_response = connect_to_endpoint(url[0], headers, url[1])\n",
        "  i = json.dumps(json_response, indent=4, sort_keys=True)                       # Recolección de la respuesta de la API de Twitter en un json\n",
        "\n",
        "\n",
        "  # Transformación del JSON devuelto por la API de Twitter en un DataFrame de la librería Pandas\n",
        "  info = json.loads(i)\n",
        "  df1 = pd.DataFrame()                                                          # Al encontrarse los diferentes campos de los tweets que se desean obtener, en diferentes niveles del fichero JSON, se ha decidido extraerlos en 3 DataFrames diferentes para cada nivel, para posteriormente unirlos en un único DataFrame final\n",
        "  df1 = json_normalize(info['data'])\n",
        "  df2 =json_normalize(info['includes'].values())\n",
        "  df3 = pd.DataFrame()\n",
        "  for j in range (0, df2.size):\n",
        "    d = pd.DataFrame.from_dict(df2[j][0], orient='index').T\n",
        "    df3 = df3.append(d)\n",
        "\n",
        "  # Normalización de DataFrame\n",
        "  df3 = df3.reset_index()\n",
        "  df3 = df3.drop(['index'], axis=1)\n",
        "\n",
        "  # Dataframes unidos\n",
        "  df1['name'] = ''\n",
        "  df1['username'] = ''\n",
        "  df1['followers_count'] = ''\n",
        "  df1['following_count'] = ''\n",
        "  df1['listed_count'] = ''\n",
        "  df1['tweet_count'] = ''\n",
        "  index1 = 0\n",
        "  for j in df1['author_id']:\n",
        "\n",
        "    index2 = 0\n",
        "    for i in df3['id']:\n",
        "      if j == i:\n",
        "        df1['name'][index1] = df3['name'][index2]\n",
        "        df1['username'][index1] = df3['username'][index2]\n",
        "        df1['followers_count'][index1] = df3['public_metrics.followers_count'][index2]\n",
        "        df1['following_count'][index1] = df3['public_metrics.following_count'][index2]\n",
        "        df1['listed_count'][index1] = df3['public_metrics.listed_count'][index2]\n",
        "        df1['tweet_count'][index1] = df3['public_metrics.tweet_count'][index2]\n",
        "        \n",
        "      index2 += 1 \n",
        "    index1 += 1\n",
        "\n",
        "  last_tweet = df1['created_at'][df1.shape[0]-1]\n",
        "  indice = indice + df1.shape[0]\n",
        "  dfen = dfen.append(df1, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracción de nuevas variables\n"
      ],
      "metadata": {
        "id": "3BS6kYqgJDjb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Método para extraer las urls contenidas en un texto"
      ],
      "metadata": {
        "id": "jLa1WDZnGTwJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QnOp4pmyyCT"
      },
      "outputs": [],
      "source": [
        "def url_redirect(string):\n",
        "    \"\"\"Extracts redirection url\"\"\"\n",
        "    url = re.findall(\"(?P<url>https?://[^\\s]+)\", string) \n",
        "    return url"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Método que elimina las urls contenidas en un texto"
      ],
      "metadata": {
        "id": "-MiwvLqSGVPj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7tLaLq9yFkG"
      },
      "outputs": [],
      "source": [
        "def url_erase(string):\n",
        "    \"\"\"Eliminates urls from text\"\"\"\n",
        "    r = re.sub(r\"http\\S+\", \"\", string)\n",
        "    return r"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, se extraen las urls contenidas en cada uno de los tweets y se almacenan en una nueva columna llamada 'twitter_url', para posteriormente eliminar las urls del texto de los tweets para que no influyan en el análisis textual\n"
      ],
      "metadata": {
        "id": "dm10HJzGDlmV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8zJkC03zdCz"
      },
      "outputs": [],
      "source": [
        "dfen['twitter_url'] = dfen['text'].apply(url_redirect)\n",
        "dfen['clean_text'] = dfen['text'].apply(url_erase)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Twitter presenta la peculiaridad de que todas las urls que se publican en sus tweets, son presentadas por medio de un acortador propio de Twitter por motivos de seguridad. Como el objetivo es extraer estas urls de cada una de las noticias recopiladas para extraer posteriormente el dominio de cada una de ellas, el cual representa el periodico digital fuente de cada noticia, es necesario crear un código que extraiga las urls originales de los acortadores propios de Twitter\n",
        "\n",
        "Debido al gran volúmen de datos que se tiene y la complejidad computacional que requiere ejecutar el siguiente código, Google Colab se bloquea, por lo que se decidió realizar guardados periodicos del dataset parcial obtenido e ir ejecutando este código en pequeños sets.\n",
        "\n",
        "En el siguiente código se muestra el código original sin guardados, como si fuera aplicado a todo el dataset original, deberá ser adaptado si se tiene el mismo problema computacional\n"
      ],
      "metadata": {
        "id": "ERTd8xpeDq8P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ71bAqfWQw6"
      },
      "outputs": [],
      "source": [
        "indice = 0\n",
        "dfen['urls'] = ''\n",
        "for i in dfen['twitter_url']:\n",
        "  if indice < 50000:\n",
        "     try:\n",
        "      r = requests.get(i[0]) \n",
        "      dfen['urls'][indice] = r.url\n",
        "      indice = indice +1\n",
        "     except:\n",
        "      dfen['urls'][indice] = '' \n",
        "      indice = indice +1\n",
        "  else: \n",
        "      break\n",
        "\n",
        "df = dfen"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se eliminan los tweets de los cuales no se ha conseguido obtener una url"
      ],
      "metadata": {
        "id": "NZoKm4peH1rx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irTFxAq5oi6p",
        "outputId": "31a75a62-dd0d-4bd3-d121-8c25cd9d70b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:6619: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return self._update_inplace(result)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "df['urls'].replace('', np.nan, inplace=True)\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Método de extracción del dominio de una URL para utilizarlo como una nueva variable en el DataFrame"
      ],
      "metadata": {
        "id": "xJoQPVX69ytg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7dOFTjWI08i"
      },
      "outputs": [],
      "source": [
        "def clean_urls(string):\n",
        "    domain = urlparse(string).netloc\n",
        "    return domain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9lQsaOdJeKy"
      },
      "outputs": [],
      "source": [
        "df['clean_urls'] = df['urls'].apply(clean_urls)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Método para la aplicación del modelo de análisis de sentimientos sobre texto pasado como parámetro"
      ],
      "metadata": {
        "id": "xPmEWPm8-Hwh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7LTblUmpeWP"
      },
      "outputs": [],
      "source": [
        "sid = SentimentIntensityAnalyzer()\n",
        "def vader_sentiment(text):\n",
        "    \"\"\" Calculate and return the nltk vader (lexicon method) sentiment \"\"\"\n",
        "    return sid.polarity_scores(text)['compound']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicación del método de análisis de sentimiento sobre la variable textual de cada uno de los tweets del DataFrame"
      ],
      "metadata": {
        "id": "rZ35MeBM-h6v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yQuwTjd-tXC"
      },
      "outputs": [],
      "source": [
        "df['vader compound'] = df['clean_text'].apply(vader_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyEBaUYVwz-M"
      },
      "outputs": [],
      "source": [
        "def count_words(text):\n",
        "    \"\"\"Devuelve el número de palabras que contiene cada tweet\"\"\"\n",
        "    return len(text.split())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se aplica el contador de palabras de cada tweet y se almacena el resultado en una nueva columna"
      ],
      "metadata": {
        "id": "giMuTNlxQooM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6XkzKi_yHh5"
      },
      "outputs": [],
      "source": [
        "df['num_words'] = df['text'].apply(count_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se crea un escalador para convertir el número de palabras de cada tweet en un valor comprendido entre [-1,1]"
      ],
      "metadata": {
        "id": "zxdiWm5jQ53P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4B0MVgkDygl8"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "columns_to_scale = ['num_words']\n",
        "scaler.fit(df[columns_to_scale])\n",
        "df[columns_to_scale] = scaler.transform(df[columns_to_scale])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamiento textual y Word Embedding"
      ],
      "metadata": {
        "id": "L-TZdrXpYNIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se aplica el tokenizado, y la eliminación de stopwords y signos de puntuación sobre el texto"
      ],
      "metadata": {
        "id": "Ftgh56STX8hC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation = list(punctuation)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "vocab = []\n",
        "df['tokens'] = ''\n",
        "for tweet in range(0,49097):    \n",
        "  word_tokens = word_tokenize(df['clean_text'][tweet])\n",
        "  filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "    \n",
        "  filtered_sentence = []\n",
        "    \n",
        "  for w in word_tokens:\n",
        "      if (w not in stop_words and w not in punctuation):\n",
        "          filtered_sentence.append(w)\n",
        "          if w not in vocab:\n",
        "            vocab.append(w)\n",
        "  df['tokens'][tweet] = filtered_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syO3xlFhsCcQ",
        "outputId": "d7da9bf7-821a-4c50-98f4-8e3de95dfef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Cramer', \"'s\", 'lightning', 'round', ':', 'I', 'like', 'Blackstone', 'over', 'KKR', '#', 'news', '#', 'topstories', '#', 'berkleybearnews']\n",
            "['Cramer', \"'s\", 'lightning', 'round', 'I', 'like', 'Blackstone', 'KKR', 'news', 'topstories', 'berkleybearnews']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se crea un Stemmer de tipo Porter, para realizar el proceso de Stemming sobre cada uno de los tokens creados anteriormente a partir del texto"
      ],
      "metadata": {
        "id": "NpPBrZVJRPw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer() \n",
        "df['tokenize_stemm'] = df['tokens'].apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
        "\n",
        "# Volvemos a juntar los tokens\n",
        "for i in range(len(df['tokenize_stemm'])):\n",
        "    df['tokenize_stemm'][i] = ' '.join(df['tokenize_stemm'][i])    \n",
        "df['tidy_tweet'] = df['tokenize_stemm']\n"
      ],
      "metadata": {
        "id": "HDaUqWZx_E1D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005c513f-7993-467a-951e-dec74810d500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algunas urls de las obtenidas anteriormente, son enlaces a grupos o cuentas de telegram, identificadas por un acortador 't.me', por lo que estos tweets que presentan esta característica son descartados del dataset ya que no aportan información sobre el origen de la noticia\n"
      ],
      "metadata": {
        "id": "pkQ4kxO6Ui86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,25):\n",
        "  if 't.me' in df['clean_urls'][i]:\n",
        "    df = df.drop(i, axis=0)\n",
        "df.reset_index(inplace=True,drop=True)\n",
        "df = df.drop(['index'],axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "TaGVLvQO1I-y",
        "outputId": "12fc26c4-cdc4-4bc0-f815-614d419f6f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-5a862d0a742b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#print(df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4911\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4912\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4913\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4914\u001b[0m         )\n\u001b[1;32m   4915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['index'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se tokeniza de nuevo el texto de cada tweet tras haber aplicado el stemming"
      ],
      "metadata": {
        "id": "pJwbtpcwVUo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['tokenized_tweet'] = df['tidy_tweet'].apply(lambda x: x.split()) # tokenizing "
      ],
      "metadata": {
        "id": "aZZxuVs4QfNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se selecciona un pequeño conjunto del dataset original para ser utilizado como dataset de validación, el cual va a ser etiquetado manualmente, para posteriormente comprobar si los resultados del clustering han sido acertados"
      ],
      "metadata": {
        "id": "1kcorkK5SeqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid = df.iloc[:10,:] #99,:]"
      ],
      "metadata": {
        "id": "PbKNxFvsW4o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se crea el modelo de Word2Vec que se va a utilizar para convertir cada uno de los tweets en un vector que represente el texto de esos tweets"
      ],
      "metadata": {
        "id": "fUVZ-V29Vrz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_w2v = gensim.models.Word2Vec(\n",
        "            df['tokenized_tweet'],\n",
        "            size=500, # desired no. of features/independent variables\n",
        "            window=5, # context window size\n",
        "            min_count=2, # Ignores all words with total frequency lower than 2.                                  \n",
        "            sg = 1, # 1 for skip-gram model\n",
        "            hs = 0,\n",
        "            negative = 10, # for negative sampling\n",
        "            workers= 32, # no.of cores\n",
        "            seed = 34\n",
        ") \n",
        "\n",
        "model_w2v.train(df['tokenized_tweet'], total_examples= len(df['tidy_tweet']), epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "440tWaT0_9i1",
        "outputId": "8ce54296-eaef-41da-c5fd-a6347fda8cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(429, 6520)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez definido y entrenado el modelo Word2Vec con nuestro conjunto de datos textuales, se crea este método para generar el vector de representación de cada tweet, y posteriormente, se aplica y se guarda en formato DataFrame para poder ser añadido al resto de datos que se tienen del dataset original"
      ],
      "metadata": {
        "id": "_tbdlCgrWdtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_vector(tokens, size):\n",
        "    vec = np.zeros(size).reshape((1, size))\n",
        "    count = 0\n",
        "    for word in tokens:\n",
        "        try:\n",
        "            vec += model_w2v[word].reshape((1, size))\n",
        "            count += 1.\n",
        "        except KeyError:  \n",
        "            continue\n",
        "    if count != 0:\n",
        "        vec /= count\n",
        "    return vec"
      ],
      "metadata": {
        "id": "__jXQH70Co1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordvec_arrays = np.zeros((len(df['tokenized_tweet']), 500)) \n",
        "for i in range(len(df['tokenized_tweet'])):\n",
        "    wordvec_arrays[i,:] = word_vector(df['tokenized_tweet'][i], 500)\n",
        "wordvec_df = pd.DataFrame(wordvec_arrays)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR2KrCGSCsWz",
        "outputId": "b66dae37-6ead-47f1-f95a-edb8e6609eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamiento de datos categóricos"
      ],
      "metadata": {
        "id": "m-iqfiiCYcR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se seleccionan todas las columnas del dataset original que van a ser utilizadas para el análisis, menos la parte textual que se encuentra ya almacenada en un DataFrame aparte, como se ha visto en la celda anterior"
      ],
      "metadata": {
        "id": "XFfQ6U3fW-I5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['num_words','username','vader compound','clean_urls','author_id','followers_count', 'following_count', 'listed_count', 'tweet_count']\n",
        "dataset = df[features]"
      ],
      "metadata": {
        "id": "r2DWIsMtFex3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se aplica un Label Encoder para transformar cada una de las columnas que contienen datos de tipo categórico textual en columnas con datos numéricos que representan dichos mismos datos categóricos"
      ],
      "metadata": {
        "id": "IeiO7pI_Y3mN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "dataset[\"username_labeled\"] = le.fit_transform(dataset[\"username\"])\n",
        "dataset['clean_urls_labeled'] = le.fit_transform(dataset['clean_urls'])\n",
        "dataset.drop(['username','clean_urls'], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "id": "_4H8dOC70Gi1",
        "outputId": "e37fe857-062b-4524-abc0-c01ab1315c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    num_words  vader compound            author_id followers_count  \\\n",
              "0    0.310345          0.0000  1168765575654453248              20   \n",
              "1    0.034483          0.0000  1379367732383154177             158   \n",
              "2   -0.655172          0.5106            454478622             541   \n",
              "3    0.448276         -0.6369  1252396121294602240              34   \n",
              "4   -0.586207          0.0000  1514149588252385286            1825   \n",
              "5    0.793103         -0.3400           3265583034            3547   \n",
              "6   -0.448276          0.0000  1125833315402100740             557   \n",
              "7   -0.586207          0.4926           3849691696             690   \n",
              "8   -0.103448          0.0000  1379367732383154177             158   \n",
              "9   -0.103448          0.0000  1031294099696050176             378   \n",
              "10   0.034483          0.7430              7228352            5606   \n",
              "11  -0.310345          0.0000            100779526           94270   \n",
              "12  -0.724138          0.0000             64815770            1523   \n",
              "13  -0.517241          0.0000             26350330           42816   \n",
              "14  -0.241379         -0.4588  1514149588252385286            1825   \n",
              "15  -0.862069          0.4926             25801797            1284   \n",
              "16  -0.310345          0.4767            715260608             132   \n",
              "17  -0.310345          0.4019  1379367732383154177             158   \n",
              "18  -0.724138          0.0000            454248267              12   \n",
              "19  -1.000000          0.0000           3065786977             210   \n",
              "20  -0.310345          0.4019  1346353472183013376            1550   \n",
              "21  -0.448276          0.0000            454478622             541   \n",
              "22  -0.655172          0.3612            787546010            1759   \n",
              "\n",
              "   following_count listed_count tweet_count  username_labeled  \\\n",
              "0               12            0       11291                17   \n",
              "1              535            2       95451                10   \n",
              "2              525          223      124912                11   \n",
              "3                4            0       55197                18   \n",
              "4             4303            0       46152                 2   \n",
              "5             1815          143      126251                 0   \n",
              "6              945            0        4630                 3   \n",
              "7             1850            3        7036                 6   \n",
              "8              535            2       95451                10   \n",
              "9               84           10       19359                 4   \n",
              "10            6141          160      413778                16   \n",
              "11           52890          438      736943                 8   \n",
              "12             648          120      152044                 7   \n",
              "13             590         1294      151065                13   \n",
              "14            4303            0       46152                 2   \n",
              "15            2216           65        5980                15   \n",
              "16             220           13       62417                14   \n",
              "17             535            2       95451                10   \n",
              "18             215            0         865                 5   \n",
              "19             378            8        6004                12   \n",
              "20               4           26       24645                 9   \n",
              "21             525          223      124912                11   \n",
              "22             191          255     2153962                 1   \n",
              "\n",
              "    clean_urls_labeled  \n",
              "0                   15  \n",
              "1                    5  \n",
              "2                   14  \n",
              "3                   18  \n",
              "4                    2  \n",
              "5                    0  \n",
              "6                   16  \n",
              "7                    7  \n",
              "8                    5  \n",
              "9                    1  \n",
              "10                  13  \n",
              "11                   7  \n",
              "12                  11  \n",
              "13                   6  \n",
              "14                   3  \n",
              "15                   7  \n",
              "16                   4  \n",
              "17                   5  \n",
              "18                   8  \n",
              "19                  17  \n",
              "20                  12  \n",
              "21                   9  \n",
              "22                  10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28b9abe2-1fb8-40e1-846c-9e6abf643bb6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_words</th>\n",
              "      <th>vader compound</th>\n",
              "      <th>author_id</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>following_count</th>\n",
              "      <th>listed_count</th>\n",
              "      <th>tweet_count</th>\n",
              "      <th>username_labeled</th>\n",
              "      <th>clean_urls_labeled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.310345</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1168765575654453248</td>\n",
              "      <td>20</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>11291</td>\n",
              "      <td>17</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1379367732383154177</td>\n",
              "      <td>158</td>\n",
              "      <td>535</td>\n",
              "      <td>2</td>\n",
              "      <td>95451</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.655172</td>\n",
              "      <td>0.5106</td>\n",
              "      <td>454478622</td>\n",
              "      <td>541</td>\n",
              "      <td>525</td>\n",
              "      <td>223</td>\n",
              "      <td>124912</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.448276</td>\n",
              "      <td>-0.6369</td>\n",
              "      <td>1252396121294602240</td>\n",
              "      <td>34</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>55197</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.586207</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1514149588252385286</td>\n",
              "      <td>1825</td>\n",
              "      <td>4303</td>\n",
              "      <td>0</td>\n",
              "      <td>46152</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.793103</td>\n",
              "      <td>-0.3400</td>\n",
              "      <td>3265583034</td>\n",
              "      <td>3547</td>\n",
              "      <td>1815</td>\n",
              "      <td>143</td>\n",
              "      <td>126251</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.448276</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1125833315402100740</td>\n",
              "      <td>557</td>\n",
              "      <td>945</td>\n",
              "      <td>0</td>\n",
              "      <td>4630</td>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.586207</td>\n",
              "      <td>0.4926</td>\n",
              "      <td>3849691696</td>\n",
              "      <td>690</td>\n",
              "      <td>1850</td>\n",
              "      <td>3</td>\n",
              "      <td>7036</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.103448</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1379367732383154177</td>\n",
              "      <td>158</td>\n",
              "      <td>535</td>\n",
              "      <td>2</td>\n",
              "      <td>95451</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.103448</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1031294099696050176</td>\n",
              "      <td>378</td>\n",
              "      <td>84</td>\n",
              "      <td>10</td>\n",
              "      <td>19359</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.7430</td>\n",
              "      <td>7228352</td>\n",
              "      <td>5606</td>\n",
              "      <td>6141</td>\n",
              "      <td>160</td>\n",
              "      <td>413778</td>\n",
              "      <td>16</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-0.310345</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100779526</td>\n",
              "      <td>94270</td>\n",
              "      <td>52890</td>\n",
              "      <td>438</td>\n",
              "      <td>736943</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>-0.724138</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>64815770</td>\n",
              "      <td>1523</td>\n",
              "      <td>648</td>\n",
              "      <td>120</td>\n",
              "      <td>152044</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>-0.517241</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>26350330</td>\n",
              "      <td>42816</td>\n",
              "      <td>590</td>\n",
              "      <td>1294</td>\n",
              "      <td>151065</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-0.241379</td>\n",
              "      <td>-0.4588</td>\n",
              "      <td>1514149588252385286</td>\n",
              "      <td>1825</td>\n",
              "      <td>4303</td>\n",
              "      <td>0</td>\n",
              "      <td>46152</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-0.862069</td>\n",
              "      <td>0.4926</td>\n",
              "      <td>25801797</td>\n",
              "      <td>1284</td>\n",
              "      <td>2216</td>\n",
              "      <td>65</td>\n",
              "      <td>5980</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-0.310345</td>\n",
              "      <td>0.4767</td>\n",
              "      <td>715260608</td>\n",
              "      <td>132</td>\n",
              "      <td>220</td>\n",
              "      <td>13</td>\n",
              "      <td>62417</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>-0.310345</td>\n",
              "      <td>0.4019</td>\n",
              "      <td>1379367732383154177</td>\n",
              "      <td>158</td>\n",
              "      <td>535</td>\n",
              "      <td>2</td>\n",
              "      <td>95451</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>-0.724138</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>454248267</td>\n",
              "      <td>12</td>\n",
              "      <td>215</td>\n",
              "      <td>0</td>\n",
              "      <td>865</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>3065786977</td>\n",
              "      <td>210</td>\n",
              "      <td>378</td>\n",
              "      <td>8</td>\n",
              "      <td>6004</td>\n",
              "      <td>12</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>-0.310345</td>\n",
              "      <td>0.4019</td>\n",
              "      <td>1346353472183013376</td>\n",
              "      <td>1550</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>24645</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>-0.448276</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>454478622</td>\n",
              "      <td>541</td>\n",
              "      <td>525</td>\n",
              "      <td>223</td>\n",
              "      <td>124912</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>-0.655172</td>\n",
              "      <td>0.3612</td>\n",
              "      <td>787546010</td>\n",
              "      <td>1759</td>\n",
              "      <td>191</td>\n",
              "      <td>255</td>\n",
              "      <td>2153962</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28b9abe2-1fb8-40e1-846c-9e6abf643bb6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28b9abe2-1fb8-40e1-846c-9e6abf643bb6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28b9abe2-1fb8-40e1-846c-9e6abf643bb6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se realiza un escalado de todas las columnas de datos categórigcos a un rango de valores comprendido entre [-1,1] al igual que se realizó previamente con la columna que contiene el número de palabras de cada tweet, y como es representado también por la columna de análisis de sentimiento generada con anterioridad"
      ],
      "metadata": {
        "id": "spHxpy6NZWI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "columns_to_scale = ['username_labeled', 'clean_urls_labeled','followers_count', 'following_count', 'listed_count', 'tweet_count']\n",
        "scaler.fit(dataset[columns_to_scale])\n",
        "dataset[columns_to_scale] = scaler.transform(dataset[columns_to_scale])\n",
        "dataset = dataset.drop(['username','clean_urls'], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNBJ8zXMM1KC",
        "outputId": "fb4f3596-cc75-41c8-a9b8-e754b2bcc0ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[col] = igetitem(value, i)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unión de los dos dataset generados, el que contiene los datos categórigcos ya preprocesados y escalados, y el que contiene la representación vectorial de cada uno de los tweets"
      ],
      "metadata": {
        "id": "uf3m4kJZaI9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dat = pd.concat([dataset, wordvec_df], axis=1)"
      ],
      "metadata": {
        "id": "QG2nExZJLtRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se aplica un Principal Component Analysis para eliminar las variables del dataset que aportan menor información al análisis"
      ],
      "metadata": {
        "id": "hVpOO3osakXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 255)\n",
        "p = pca.fit_transform(dat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "5Ao0J_RGnjcR",
        "outputId": "acea0105-6998-4826-eb98-ed44ad993d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-5491413a4887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Transform the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m'np.ascontiguousarray'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \"\"\"\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"full\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"arpack\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"randomized\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0;34m\"n_components=%r must be between 0 and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;34m\"min(n_samples, n_features)=%r with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                 \u001b[0;34m\"svd_solver='full'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m             )\n\u001b[1;32m    480\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: n_components=255 must be between 0 and min(n_samples, n_features)=23 with svd_solver='full'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelos de aprendizaje y resultados"
      ],
      "metadata": {
        "id": "lnwVvZQ1biHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación se van a ejecutar los diferentes modelos que se van a probar en el análisis además de mostrar los resultados que presentan cada uno de ellos\n"
      ],
      "metadata": {
        "id": "TbOLOa8Ybz-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kmeans**\n",
        "\n",
        "Se ejecuta el modelo Kmeans buscando en este caso 3 clusters diferentes, que representan las noticias falsas, las verdaderas y un tercer grupo que son noticias de propaganda que no son en su completitud falsas"
      ],
      "metadata": {
        "id": "w8nYg03Tb9kl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fF0EPYCjmShS"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(3, init='random')\n",
        "label = kmeans.fit_predict(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impresión de gráfico con los diferentes clusters detectados"
      ],
      "metadata": {
        "id": "asE3UJlTNm4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u_labels = np.unique(label)\n",
        " \n",
        "for i in u_labels:\n",
        "    plt.scatter(p[label == i , 0] , p[label == i , 1] , label = i)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "f3c742ec-c151-4eb1-b7b1-283ffddc10d2",
        "id": "FZvf32ceG0Jr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-41e6d4d4ec79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation**\n",
        "\n",
        "Se ejecuta el modelo de Propagación de afinidad al cual no se le introducen el número de clusters que se quiere identificar, de manera que lo que se busca mediante este modelo es ver cuantos clusters diferentes es capaz de identificar"
      ],
      "metadata": {
        "id": "5zJ6pjW_epd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ap = AffinityPropagation(damping=0.9,random_state=5).fit(p)\n",
        "label = ap.predict(p)"
      ],
      "metadata": {
        "id": "EeDM1xleKCl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_labels = np.unique(label)\n",
        "\n",
        "for i in u_labels:\n",
        "    plt.scatter(p[label == i , 0] , p[label == i , 1] , label = i)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "f3c742ec-c151-4eb1-b7b1-283ffddc10d2",
        "id": "c_SrD7KGG18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-41e6d4d4ec79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aglomerative Clustering**\n",
        "\n",
        "Se ejecuta el modelo de Clustering aglomerativo al cual sí hay que proporcionarle el número de clusters que se desea obtener"
      ],
      "metadata": {
        "id": "kKU2aweufV9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agC = AgglomerativeClustering(3)\n",
        "label = agC.fit_predict(p)"
      ],
      "metadata": {
        "id": "x3eZYZz8If7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_labels = np.unique(label)\n",
        "\n",
        "for i in u_labels:\n",
        "    plt.scatter(p[label == i , 0] , p[label == i , 1] , label = i)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "f3c742ec-c151-4eb1-b7b1-283ffddc10d2",
        "id": "Zjz4GWvvG2kd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-41e6d4d4ec79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Birch**\n",
        "\n",
        "Se ejecuta el modelo de Birch al cual sí hay que proporcionarle el número de clusters que se desea obtener"
      ],
      "metadata": {
        "id": "pfMutaTyfkOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "birch = Birch(n_clusters=3)\n",
        "label = birch.fit_predict(p)"
      ],
      "metadata": {
        "id": "Ve6d2M_-YsJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_labels = np.unique(label)\n",
        "\n",
        "for i in u_labels:\n",
        "    plt.scatter(p[label == i , 0] , p[label == i , 1] , label = i)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "f3c742ec-c151-4eb1-b7b1-283ffddc10d2",
        "id": "b-iiBkfcG3Gt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-41e6d4d4ec79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DBSCAN**\n",
        "\n",
        "Se ejecuta el modelo de DBSCAN, basado en densidad, al cual no hay que proporcionarle el número de clusters que se desea obtener"
      ],
      "metadata": {
        "id": "4lF5VioLfnz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dbscan = DBSCAN()\n",
        "label = birch.fit_predict(p)"
      ],
      "metadata": {
        "id": "BqHRPM_ZZAzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_labels = np.unique(label)\n",
        "\n",
        "for i in u_labels:\n",
        "    plt.scatter(p[label == i , 0] , p[label == i , 1] , label = i)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "f3c742ec-c151-4eb1-b7b1-283ffddc10d2",
        "id": "qwfvydZmG3i5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-41e6d4d4ec79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MeanShift**\n",
        "\n",
        "Se ejecuta el modelo de MeanShift al cual no hay que proporcionarle el número de clusters que se desea obtener"
      ],
      "metadata": {
        "id": "MHsBqPj3fwQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = MeanShift()\n",
        "label = mean.fit_predict(p)"
      ],
      "metadata": {
        "id": "D6axHaOdq7HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_labels = np.unique(label)\n",
        "\n",
        "for i in u_labels:\n",
        "    plt.scatter(p[label == i , 0] , p[label == i , 1] , label = i)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "f3c742ec-c151-4eb1-b7b1-283ffddc10d2",
        "id": "QjN8GNsxG4Ga"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-41e6d4d4ec79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mini Batch Kmeans**\n",
        "\n",
        "Se ejecuta el modelo de Mini Batch Kmeans al cual sí hay que proporcionarle el número de clusters que se desea obtener"
      ],
      "metadata": {
        "id": "E4GEbSArf1N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mini =MiniBatchKMeans(n_clusters=3,random_state=32,batch_size=6)\n",
        "label = mini.fit_predict(p)"
      ],
      "metadata": {
        "id": "Ek3H6s_Jz9DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_labels = np.unique(label)\n",
        "\n",
        "for i in u_labels:\n",
        "    plt.scatter(p[label == i , 0] , p[label == i , 1] , label = i)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "f3c742ec-c151-4eb1-b7b1-283ffddc10d2",
        "id": "kN7RMCWmG4so"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-41e6d4d4ec79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OPTICS**\n",
        "\n",
        "Se ejecuta el modelo de OPTICS al cual no hay que proporcionarle el número de clusters que se desea obtener"
      ],
      "metadata": {
        "id": "Cgv3OZldf89B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = OPTICS(min_samples=2)\n",
        "label = opt.fit_predict(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFjrfT7i1-T2",
        "outputId": "2c44ed4f-5c17-473a-9a94-1372db07c3b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_optics.py:903: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u_labels = np.unique(label)\n",
        " \n",
        "for i in u_labels:\n",
        "    plt.scatter(p[label == i , 0] , p[label == i , 1] , label = i)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "f3c742ec-c151-4eb1-b7b1-283ffddc10d2",
        "id": "RA0h3YqyG5Su"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-41e6d4d4ec79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spectral Clustering**\n",
        "\n",
        "Se ejecuta el modelo de Clustering espectral, al cual sí hay que proporcionarle el número de clusters que se desea obtener"
      ],
      "metadata": {
        "id": "-vuKE38YgB_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spec = SpectralClustering(n_clusters=3)\n",
        "label = spec.fit_predict(p)"
      ],
      "metadata": {
        "id": "RdXwgzcf3DdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ead542e-15ab-4d3c-f345-2866c57da641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_spectral_embedding.py:261: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  \"Graph is not fully connected, spectral embedding may not work as expected.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u_labels = np.unique(label)\n",
        "\n",
        "for i in u_labels:\n",
        "    plt.scatter(p[label == i , 0] , p[label == i , 1] , label = i)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "f3c742ec-c151-4eb1-b7b1-283ffddc10d2",
        "id": "Pf1jvSo7G5zJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-41e6d4d4ec79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gaussian Mixture**\n",
        "\n",
        "Se ejecuta el modelo de Mezcla de gaussianas, al cual no hay que proporcionarle el número de clusters que se desea obtener"
      ],
      "metadata": {
        "id": "a_2qewT6gKNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gau = GaussianMixture(n_components=3)\n",
        "label = gau.fit_predict(p)"
      ],
      "metadata": {
        "id": "LJ2qbXSq3E0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_labels = np.unique(label)\n",
        "\n",
        "for i in u_labels:\n",
        "    plt.scatter(p[label == i , 0] , p[label == i , 1] , label = i)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "f3c742ec-c151-4eb1-b7b1-283ffddc10d2",
        "id": "SEJq8S-XG6aS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-41e6d4d4ec79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cálculo de métricas "
      ],
      "metadata": {
        "id": "gNQk_GLcICoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sil_scores = []\n",
        "se = []\n",
        "calinski_score = []\n",
        "davies_score = []\n",
        "se.append(kmeans.inertia_)\n",
        "sil_scores.append(silhouette_score(p, label))\n",
        "calinski_score.append(calinski_harabasz_score(p, label))\n",
        "davies_score.append(davies_bouldin_score(p, label))\n",
        "\n",
        "print('Silhouette score:', sil_scores)"
      ],
      "metadata": {
        "id": "RFIb4itVm56E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "1d8faae8-e959-44c4-eb9e-7ea22160d57d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-cd0e6a0fcb0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcalinski_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdavies_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msil_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilhouette_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcalinski_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalinski_harabasz_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'kmeans' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}